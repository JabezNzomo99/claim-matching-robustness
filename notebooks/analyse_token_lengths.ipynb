{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to evaluate the distribution of fact check lengths to determine appropriate token length for Gemma\n",
    "# Add library support\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "import json\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "# Test whether checkthat parsing works correctly\n",
    "from claimrobustness import utils, defaults\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the targets\n",
    "# Load the test data used for generating misinformation edits\n",
    "data = utils.load_data(dataset='fact-check-tweet')\n",
    "test_queries, test_qrels = data[\"test\"]\n",
    "targets = data[\"targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ranks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rank = test_ranks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rank[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sample_rank).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many indices in sample_rank are present in targets.index\n",
    "present_indices = [idx for idx in sample_rank if idx in targets.index]\n",
    "num_present_indices = len(present_indices)\n",
    "\n",
    "print(f\"Number of indices in sample_rank that are present in targets.index: {num_present_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-v2-gemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = targets['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', train_sentences[11])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(train_sentences[10]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_sentences[10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the maximum length of the sentences\n",
    "max_len = 0\n",
    "lengths_en = []\n",
    "# For every sentence...\n",
    "for sent in train_sentences:\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    # Record the length.\n",
    "    lengths_en.append(len(input_ids))\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min length: {:,} tokens'.format(min(lengths_en)))\n",
    "print('Max length: {:,} tokens'.format(max(lengths_en)))\n",
    "print('Median length: {:,} tokens'.format(int(np.median(lengths_en))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the distribution of sequence lengths\n",
    "\n",
    "custom_palette = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "\n",
    "# Set style for scientific publications\n",
    "sns.set_theme(style='white', font_scale=1.0)  # Reduced font scale\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Increase the plot size and font size\n",
    "sns.set(font_scale=1)\n",
    "# Create the plot with a white background\n",
    "plt.figure(figsize=(10.5, 4.27), facecolor='white')\n",
    "\n",
    "# Plot the distribution of sequence lengths without grids\n",
    "sns.distplot(lengths_en, kde=False, rug=False, hist_kws={'alpha': 1, 'edgecolor': 'black'})\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of Sequence Lengths After including Context')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Number of Samples')\n",
    "\n",
    "# Emphasize the x-axis and y-axis\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Keep only left and bottom border lines\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()  # Ensures labels don't overlap\n",
    "# plt.savefig(\"sequence_lengths_distribution_with_context.svg\", dpi=300)  # Save the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 2048\n",
    "\n",
    "# Count the number of sequences that are longer than `max_len` tokens.\n",
    "num_truncated = np.sum(np.greater(lengths_en, max_len))\n",
    "\n",
    "# Compare this to the total number of training sentences.\n",
    "num_sentences = len(lengths_en)\n",
    "prcnt = float(num_truncated) / float(num_sentences)\n",
    "\n",
    "print('{:,} of {:,} sentences ({:.1%}) in the training set are longer than {:} tokens.'.format(num_truncated, num_sentences, prcnt, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the maximum length\n",
    "max_length = tokenizer.model_max_length\n",
    "print(f\"Maximum tokenizer length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
