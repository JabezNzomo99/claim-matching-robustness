{"title": "Analysis | How Russia weaponized social media, got caught and escaped consequences", "subtitle": "Russia weaponized social media in an attempt to influence the 2016 presidential election. But its efforts didn't end after it was caught.", "author": "www.washingtonpost.com", "date": "2019-11-18T08:00:17.351Z", "vclaim_id": "vclaim-id-86311", "url": "https://www.washingtonpost.com/politics/2019/11/18/how-russia-weaponized-social-media-got-caught-escaped-consequences/", "vclaim": "At this point, it\u2019s old news that Russia tried to influence the 2016 presidential election. Not long after the election, the Obama administration imposed sanctions on Russia, including the expulsion of Russian intelligence operatives. Then-FBI Director James B. Comey confirmed there was an open investigation into Russian interference in the 2016 election six months later. And Russian operatives were indicted in 2018. This year, the report by special counsel Robert S. Mueller III put it all in print: Russia used email leaks, propaganda and social media to stoke societal divisions and undermine the integrity of the election process in the United States.\n\nStill, Russia\u2019s use of strategic propaganda is part of a decades-old playbook. What is new is how cleanly, simply and effectively it was able to distribute false information, manipulate mainstream media and amplify existing divisions using social media platforms. However, 2016 was not the first election in which social media played a role \u2014 so what changed? Why were Russian operatives able to amplify their message so clearly? And what does that mean for the 2020 election?\n\n\u201cThey would create campaigns on different platforms and target different subgroups using the data-targeting capabilities of those platforms,\u201d said Dave Carroll, a professor of media design at Parsons School of Design. The agency iterated and evolved its targeting techniques. Ultimately, it developed what Carroll described as a \u201csophisticated understanding of who uses the platforms, what they use them for and what messages might resonate best on those platforms. And then how to use the targeted capabilities of those platforms to test their own messages and hone with greater effectiveness.\u201d\n\n\u201cWhat we have here is a multi-strategy, multithreaded approach to influencing and to dividing. And they are using the best tool at their disposal to do that. And that\u2019s not always in coordination, but it potentially could be someday,\u201d said Renee DiResta, technical research manager at the Stanford Internet Observatory and co-author of a recent report on GRU online operations.\n\nBy 2016, Russia had started more than 20 campaigns in 13 countries. Forty percent of these campaigns were on Facebook and nearly 90 percent were on Twitter, according to a report from Jacob Shapiro and Diego Martin at Princeton University\u2019s Empirical Studies of Conflict Project. Shapiro and Martin reported that the campaigns often appeared across platforms, including on fake websites, Reddit, Instagram, WhatsApp and in Russian-controlled media. In other words, the campaigns worked just like a targeted digital advertising campaign. They were able to buy ads on Facebook from St. Petersburg in Russian currency and run them on Facebook.\n\nInformation operations also moved platforms. Shapiro found the total number of foreign election influence efforts declined in news outlets, on Twitter and on Facebook after 2017. While there were fewer operations on Instagram, YouTube and other platforms, those efforts remained steady and slightly expanded in 2017 and 2018. Still, most campaigns appeared across platforms. It is not clear whether the move to smaller platforms like blogs, 4chan and Reddit was a result of less regulation, shift in audience or simply a need for operatives to reach a certain number of views. After all, as Shapiro explained, operators at the Internet Research Agency may have \u201can output-based measure\u201d that requires them to post a certain amount of content.\n\nHowever, foreign actors have found new ways to work around Facebook\u2019s authentication processes. They recruit people who are from and living in the country they are targeting to post or share content that ordinarily the foreign actor\u2019s accounts would have spread. For example, a Russian operative might try to convince an American to knowingly or unknowingly share Russian propaganda. By doing that, they can ensure the content makes it into the conversation without risking Facebook taking down the account or page. Foreign operators have also continued to target legitimate journalists with strategic content in an attempt to push their narrative into the wider media ecosystem.\n\nStill, there is no new legislation to govern political digital advertising, and there is no question that digital advertising will be a force in the 2020 election. (Since May 2018, Google and Facebook have sold nearly $1 billion worth of digital ads.) The question is whether a new start-up, Russian or otherwise, will seek to exploit new vulnerabilities across government, journalism and social media in the 2020 election that have not been identified yet or have not yet been addressed.", "lang": "en"}