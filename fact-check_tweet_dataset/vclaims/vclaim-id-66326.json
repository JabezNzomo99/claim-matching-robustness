{"title": "PolitiFact - Is your Amazon Alexa spying on you?", "subtitle": "Once the stuff of science fiction, voice-activated virtual assistants like the Amazon Echo, Google Home and Apple HomePo", "author": "www.politifact.com", "date": null, "vclaim_id": "vclaim-id-66326", "url": "http://www.politifact.com/truth-o-meter/statements/2018/may/31/ro-khanna/your-amazon-alexa-spying-you/", "vclaim": "Once the stuff of science fiction, voice-activated virtual assistants like the Amazon Echo, Google Home and Apple HomePod now reside in millions of American homes, tweaking thermostats, streaming music and scheduling appointments.\n\nWhile some see these devices as helping hands, others view them as Trojan horses in the age of digital surveillance.\n\n\"It is outrageous that the Amazon Echo is recording every conversation in a person\u2019s home and transmitting it to the cloud,\" Rep. Ro Khanna, D-Calif., tweeted May 26. \"This is exactly why we need an internet bill of rights! Didn\u2019t we fight a revolution to prevent exactly this kind of surveillance?\"\n\nIs Khanna correct about the scope of smart speakers\u2019 electronic eavesdropping? We decided to take a closer look.\n\nAmazon\u2019s voice-controlled Alexa products are considered \"always-on\" devices \u2014 but that doesn\u2019t mean they record customers\u2019 conversations.\n\nThe devices constantly listen for a user to say a \"wake word,\" which triggers Alexa to begin recording voice data and respond to commands. Wake words include \"Alexa,\" \"O.K. Google,\" and \"Hey Siri.\"\n\nThe Amazon Echo \u2014 one of the online retail giant\u2019s smart speaker product lines \u2014 uses seven microphones to listen for its wake word. According to Washington Post tech columnist Geoffrey Fowler, the Echo records a second-long snippet of ambient sound which it \"constantly discards and replaces,\" until a wake word starts the recording process. (Khanna said his claim was based on Fowler's piece.)\n\nAt least, that\u2019s how it works in theory. In practice, the wake word triggering mechanism has a track record that is far from perfect.\n\nIn one highly publicized incident, a Portland family\u2019s Alexa captured a private conversation after the voice-controlled device misheard what it thought was the wake word. It later sent the audio recording to someone in Seattle whose number was stored in the family\u2019s contact list. (Khanna\u2019s tweet referenced this story.)\n\nAmazon described the chain of events as \"an extremely rare occurrence,\" and issued the following statement:\n\n\"Echo woke up due to a word in background conversation sounding like 'Alexa.' Then, the subsequent conversation was heard as a \u2018send message\u2019 request. At which point, Alexa said out loud 'To whom?' At which point, the background conversation was interpreted as a name in the customer\u2019s contact list. Alexa then asked out loud, '[contact name], right?' Alexa then interpreted background conversation as 'right.' As unlikely as this string of events is, we are evaluating options to make this case even less likely.\"\n\nThe Washington Post\u2019s Fowler, who has an Echo, Google Home and Apple HomePod, said his devices go rogue on a regular basis.\n\n\"At least one of them starts recording, randomly, at least once per week,\" he wrote. \"It happens when they pick up a sound from the TV, or a stray bit of conversation that sounds enough like one of their wake words.\"\n\nFalse positives aside, technology experts told us it\u2019s against Amazon policy to constantly record customers\u2019 private conversations, as Khanna claimed.\n\n\"There's no proof or confirmation from Amazon that Echo products record \u2018every\u2019 conversation in a person's home,\" said Tiffany Li, a privacy attorney at Yale Law School\u2019s Information Society Project. \"Indeed, Amazon has publicly stated that the Alexa products only record after hearing users say wake words.\"\n\nBut Li noted that Amazon has been less-than-forthcoming about the circumstances surrounding its recording practices.\n\n\"It is possible that more data is being recorded than consumers know or that Amazon is willing to publicly admit,\" she said. \"Amazon is not very transparent on privacy practices related to Alexa/Echo products.\"\n\nNotwithstanding Amazon\u2019s lack of candor, Li said Khanna\u2019s claim is \"probably not accurate.\"\n\nWhen does Amazon send conversations \u2018to the cloud\u2019?\n\nOnly voice data that\u2019s recorded after a wake word is detected is sent to the cloud. So Khanna\u2019s claim creates a false impression that private conversations are being secretly routed to Amazon\u2019s computers.\n\n\"While the device is indeed always listening (there's no way for it to respond to the wake word otherwise), it is not always transmitting to the cloud,\" said Daniel Kahn Gillmor, a Senior Staff Technologist for the ACLU's Speech, Privacy, and Technology Project.\n\nStill, Gillmor expressed reservations about the degree of control Amazon maintains over the devices after they\u2019re installed in customers\u2019 homes.\n\n\"The code in that device is under the control of Amazon, and it's basically up to Amazon (not to the owner of the device) to make sure that it's not transmitting to the cloud,\" he said. \"Clearly, Amazon isn't making those decisions correctly all the time.\"\n\nKhanna said, \"Amazon Echo is recording every conversation in a person's home and transmitting it to the cloud.\"\n\nAmazon\u2019s Alexa technology is designed to capture voice data only after a specific voice command, called a wake word, triggers a recording mechanism. Despite some instances where private conversations were accidentally recorded and uploaded to the cloud, Khanna\u2019s claim greatly overstates things. We found no evidence to suggest the device records every conversation and sends it the cloud. It does record conversations when it hears the wake word, and in some cases the device has misinterpreted speech when people didn't actually say the wake work.\n\nWe rate this Mostly False.", "lang": "en"}