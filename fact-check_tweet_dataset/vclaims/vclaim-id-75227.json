{"title": "Facebook\u2019s New Anti-Fake News Strategy Is Not Going To Work \u2013 But Something Else Might", "subtitle": "Facebook\u2019s strategy is vacuous, evanescent, lip service; a public relations exercise that makes no substantive attempt to address a serious problem.", "author": "www.boomlive.in", "date": "2017-05-01T10:14:07+05:30", "vclaim_id": "vclaim-id-75227", "url": "https://www.boomlive.in/facebooks-new-anti-fake-news-strategy-is-not-going-to-work-but-something-else-might/", "vclaim": "The first part of the plan is to build new products to curb the spread of fake news stories. Facebook says it\u2019s trying \u201cto make it easier to report a false news story\u201d and find signs of fake news such as \u201cif reading an article makes people significantly less likely to share it.\u201d It will then send the story to independent fact checkers. If fake, the story \u201cwill get flagged as disputed and there will be a link to a corresponding article explaining why.\u201d This sounds pretty good, but it won\u2019t work. If non-experts could tell the difference between real news and fake news (which is doubtful), there would be no fake news problem to begin with. What\u2019s more, Facebook says: \u201cWe cannot become arbiters of truth ourselves \u2014 it\u2019s not feasible given our scale, and it\u2019s not our role.\u201d Nonsense. Facebook is like a megaphone. Normally, if someone says something horrible into the megaphone, it\u2019s not the megaphone company\u2019s fault. But Facebook is a very special kind of megaphone that listens first and then changes the volume.\n\nThe company\u2019s algorithms largely determine both the content and order of your newsfeed. So if Facebook\u2019s algorithms spread some neo-Nazi hate speech far and wide, yes, it is the company\u2019s fault. Worse yet, even if Facebook accurately labels fake news as contested, it will still affect public discourse through \u201cavailability cascades.\u201d Each time you see the same message repeated from (apparently) different sources, the message seems more believable and reasonable. Bold lies are extremely powerful because repeatedly fact-checking them can actually make people remember them as true. These effects are exceptionally robust; they cannot be fixed with weak interventions such as public service announcements, which brings us to the second part of Facebook\u2019s strategy: helping people make more informed decisions when they encounter false news.\n\nHelping you help yourself Facebook is releasing public service announcements and funding the \u201cnews integrity initiative\u201d to help \u201cpeople make informed judgments about the news they read and share online\u201d. A vast body of research in cognitive psychology concerns correcting systematic errors in reasoning such as failing to perceive propaganda and bias. We have known since the 1980s that simply warning people about their biased perceptions doesn\u2019t work. Similarly, funding a \u201cnews integrity\u201d project sounds great until you realise the company is really talking about critical thinking skills. Improving critical thinking skills is a key aim of primary, secondary and tertiary education. If four years of university barely improves these skills in students, what will this initiative do? Make some Youtube videos? A fake news FAQ?\n\nFunding a few research projects and \u201cmeetings with industry experts\u201d doesn\u2019t stand a chance to change anything. The third prong of this non-strategy is cracking down on spammers and fake accounts, and making it harder for them to buy advertisements. While this is a good idea, it\u2019s based on the false premise that most fake news comes from shady con artists rather thanmajornewsoutlets. You see, \u201cfake news\u201d is Orwellian newspeak \u2014 carefully crafted to mean a totally fabricated story from a fringe outlet masquerading as news for financial or political gain. But these stories are the most suspicious and therefore the least worrisome. Bias and lies from public figures, official reports and mainstream news are far more insidious. And what about astrology, homeopathy, psychics, anti-vaccination messages, climate change denial, intelligent design, miracles, and all the rest of the irrational nonsense bandied about online? What about the vast array of deceptive marketing and stealth advertising that is core to Facebook\u2019s business model? As of this writing, Facebook doesn\u2019t even have an option to report misleading advertisements.\n\nWhat is Facebook to do? Facebook\u2019s strategy is vacuous, evanescent, lip service; a public relations exercise that makes no substantive attempt to address a serious problem. But the problem is not unassailable. The key to reducing inaccurate perceptions is to redesign technologies to encourage more accurate perception. Facebook can do this by developing a propaganda filter \u2014 something like a spam filter for lies. Facebook may object to becoming an \u201carbiter of truth\u201d. But coming from a company that censors historic photos and comedians calling for social justice, this sounds disingenuous.\n\nAbout the author: Paul Ralph, is a Senior Lecturer in Computer Science at the University of Auckland\n\nThis article was republished from theconversation.com.", "lang": "en"}