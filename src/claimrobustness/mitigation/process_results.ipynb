{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/kebl7383/claim-matching-robustness/experiments/mitigation/gpt4o/ood-dataset/orig_ood_normalised.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df = pd.read_json(path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_normalised_claim(row):\n",
    "    \"\"\"\n",
    "    Parses the normalised claim string to extract the claim content.\n",
    "    If parsing fails, returns the original query from the row.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row of the DataFrame containing 'normalised' and 'query'.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted claim content or the original query if parsing fails.\n",
    "    \"\"\"\n",
    "    input_string = row['normalised']\n",
    "    \n",
    "    try:\n",
    "        if isinstance(input_string, str) and input_string.startswith(\"Normalised Claim:\"):\n",
    "            # Remove the prefix and trim whitespace\n",
    "            claim = input_string[len(\"Normalised Claim:\"):].strip()\n",
    "            # Remove surrounding quotes if they exist\n",
    "            if claim.startswith('\"') and claim.endswith('\"'):\n",
    "                claim = claim[1:-1]\n",
    "            return claim\n",
    "    except Exception:\n",
    "        pass  # Handle unexpected errors silently\n",
    "\n",
    "    # If parsing fails, return the original query\n",
    "    return row['query']\n",
    "\n",
    "# Apply function using DataFrame row-wise processing\n",
    "parsed_df['normalised_claim'] = parsed_df.apply(parse_normalised_claim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original claims\n",
    "pd.DataFrame(parsed_df[['query_id', 'normalised_claim']]).to_csv(\n",
    "    '/home/kebl7383/claim-matching-robustness/experiments/ood/ood-dataset/ood_normalised_queries.tsv',\n",
    "    index=False,\n",
    "    header=[\"query_id\", \"query\"],\n",
    "    sep=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare the data for plotting\n",
    "data = {\n",
    "    \"Perturbation\": [\"Typos (Most)\", \"Dialect (Pidgin)\", \"Entity Replacement (All)\"],\n",
    "    \"Unpertubed-LASER\": [0.3925368375, 0.3762761346, 0.383623902],\n",
    "    \"Unpertubed-LASER+CN\": [0.4692155375, 0.4272919467, 0.4487253053],\n",
    "    \"Perturbed-LASER\": [0.327248736, 0.3307935937, 0.3221515615],\n",
    "    \"Perturbed-LASER+CN\": [0.481794082, 0.4600243046, 0.3968193758],\n",
    "    \"Unpertubed-RoLASER\": [0.4048508585, 0.3883688138, 0.4164909542],\n",
    "    \"Unpertubed-RoLASER+CN\": [0.4239301394, 0.3980654122, 0.4168946832],\n",
    "    \"Perturbed-RoLASER\": [0.3511871528, 0.3336198569, 0.3129087056],\n",
    "    \"Perturbed-RoLASER+CN\": [0.4797898815, 0.4129593157, 0.3616379534]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cmcrameri.cm as cmc\n",
    "import matplotlib\n",
    "\n",
    "# Set font globally to Helvetica Neue\n",
    "matplotlib.rcParams['font.family'] = 'Helvetica Neue'\n",
    "plt.rcParams.update({'font.size': 16})  # Global font size\n",
    "\n",
    "\n",
    "def plot_all_comparisons(df, output_file='comparison_plot.pdf'):\n",
    "    perturbations = df[\"Perturbation\"].unique()\n",
    "    num_perturbations = len(perturbations)\n",
    "    \n",
    "    # Create a horizontal subplot for each perturbation\n",
    "    fig, axes = plt.subplots(1, num_perturbations, figsize=(6 * num_perturbations, 4), sharey=True)\n",
    "    \n",
    "    # Colormap and bar colors\n",
    "    bar_colors = ['#5DADE2', '#1B4F72', '#28B463', '#117A65']  # Navy, Green, Light Blue, Medium Green\n",
    "    scatter_colors = ['#21618C', '#5499C7', '#82E0AA', '#48C9B0']  # Contrasting colors for scatter markers\n",
    "    y_ticks = np.arange(0.30, 0.56, 0.05)  # Adjust start, end, and step size as needed\n",
    "\n",
    "    # Markers for shapes\n",
    "    markers = ['s', '^', 'h', 'o']  # Cross, Triangle, Star, Circle\n",
    "    \n",
    "    # Loop through each perturbation and plot\n",
    "    for ax, perturbation in zip(axes, perturbations):\n",
    "        row = df[df[\"Perturbation\"] == perturbation].iloc[0]\n",
    "        \n",
    "        # Define x positions for each bar\n",
    "        x_labels = ['LASER', 'LASER+CN', 'RoLASER', 'RoLASER+CN']\n",
    "        x_positions = np.arange(len(x_labels))\n",
    "        \n",
    "        # Unperturbed and perturbed data\n",
    "        unperturbed = [\n",
    "            row[\"Unpertubed-LASER\"],\n",
    "            row[\"Unpertubed-LASER+CN\"],\n",
    "            row[\"Unpertubed-RoLASER\"],\n",
    "            row[\"Unpertubed-RoLASER+CN\"]\n",
    "        ]\n",
    "        perturbed = [\n",
    "            row[\"Perturbed-LASER\"],\n",
    "            row[\"Perturbed-LASER+CN\"],\n",
    "            row[\"Perturbed-RoLASER\"],\n",
    "            row[\"Perturbed-RoLASER+CN\"]\n",
    "        ]\n",
    "        \n",
    "        # Bar width\n",
    "        bar_width = 0.50\n",
    "        \n",
    "        # Plot each bar\n",
    "        for i, (x, p, u, bar_color, scatter_color) in enumerate(zip(x_positions, perturbed, unperturbed, bar_colors, scatter_colors)):\n",
    "            ax.bar(x, p, width=bar_width, color=bar_color, alpha=0.8)\n",
    "            \n",
    "            # Add a marker for unperturbed value\n",
    "            ax.scatter(x, u, color=scatter_color, marker=markers[i], s=100, edgecolors='white', linewidth=1, label=f'{x_labels[i]} Unperturbed')\n",
    "        \n",
    "        # Add horizontal gridlines\n",
    "        for y in y_ticks:\n",
    "            ax.axhline(y=y, color='lightgray', linestyle='--', linewidth=0.3)\n",
    "        \n",
    "        for x in x_positions:\n",
    "            ax.axvline(x=x, color='lightgray', linestyle='--', linewidth=0.3)\n",
    "    \n",
    "        \n",
    "        # Set labels and title\n",
    "        ax.set_title(f'{perturbation}')\n",
    "        ax.set_xticks(x_positions)\n",
    "        ax.set_xticklabels(x_labels)\n",
    "        ax.set_yticks(y_ticks)\n",
    "        ax.set_ylim(0.30, 0.55)\n",
    "\n",
    "        # Set the box outline (spines) to grey\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('grey')\n",
    "        \n",
    "        ax.tick_params(axis='both', length=0)\n",
    "\n",
    "    \n",
    "    # Add a common y-axis label\n",
    "    fig.text(-0.005, 0.5, 'MAP@20', va='center', rotation='vertical')\n",
    "    \n",
    "    # Add a shared legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=len(x_labels), fontsize='small', bbox_to_anchor=(0.5, -0.1), frameon=False)\n",
    "    \n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    plt.savefig(output_file, format='pdf', bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot all perturbations\n",
    "plot_all_comparisons(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample CSV data (simulated based on the description)\n",
    "data = {\n",
    "    \"Model\": [\n",
    "        \"all-mpnet-v2\", \"all-mpnet-basev2-robust\", \"all-mpnet-base-v2-ft\", \"all-mpnet-basev2-robust-ft\",\n",
    "        \"all-mpnet-v2 + CN\", \"all-mpnet-basev2-robust + CN\", \"all-mpnet-base-v2-ft + CN\", \"all-mpnet-basev2-robust-ft + CN\"\n",
    "    ],\n",
    "    \"Typos\": [0.6777792947, 0.7299715423, 0.7738389936, 0.7778453705, 0.7802357695, 0.8297682036, 0.8864141811, 0.8815278637],\n",
    "    \"Entity Replacement\": [0.6634501966, 0.7741837164, 0.8048978672, 0.8113413255, 0.7465073234, 0.8383203952, 0.8653778943, 0.8863768749],\n",
    "    \"Dialect-Pidgin\": [0.651213211, 0.7962632275, 0.798595063, 0.8428588505, 0.7289621542, 0.8162026703, 0.8615482391, 0.865947589],\n",
    "    \"Negation\": [0.7365962491, 0.8122539556, 0.8538558851, 0.8422887173, 0.7930470993, 0.8236963299, 0.8748762499, 0.8531178844]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def plot_perturbations_no_xlabels(df, output_file='perturbations_no_xlabels.pdf'):\n",
    "    categories = [\"Typos\", \"Entity Replacement\", \"Dialect-Pidgin\", \"Negation\"]\n",
    "    num_categories = len(categories)\n",
    "    num_models = len(df[\"Model\"])\n",
    "    \n",
    "    # Define color map for the models\n",
    "    cmap = cm.get_cmap('plasma', num_models)\n",
    "    colors = [cmap(i) for i in range(num_models)]\n",
    "\n",
    "    # Create subplots for each perturbation type\n",
    "    fig, axes = plt.subplots(1, num_categories, figsize=(6 * num_categories, 5), sharey=True)\n",
    "    bar_width = 1.0  # Full-width bars for no spacing\n",
    "    x_positions = np.arange(len(df[\"Model\"]))  # X positions for each bar group\n",
    "\n",
    "    for ax, category in zip(axes, categories):\n",
    "        for i, model in enumerate(df[\"Model\"]):\n",
    "            ax.bar(x_positions[i], df[category][i], color=colors[i], width=bar_width, align='center', label=model if ax == axes[0] else \"\")\n",
    "        ax.set_title(category, fontsize=14)\n",
    "        ax.set_xticks([])  # Remove x-axis labels\n",
    "        # ax.set_ylabel(\"Score\", fontsize=12)\n",
    "        ax.set_ylim(0.5, 1)\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "\n",
    "\n",
    "    # Add a single legend\n",
    "    handles = [plt.Rectangle((0, 0), 1, 1, color=colors[i]) for i in range(num_models)]\n",
    "    fig.legend(handles, df[\"Model\"], loc='upper center', ncol=num_models, bbox_to_anchor=(0.5, 1.15), fontsize=14)\n",
    "\n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(output_file, format='pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to create the plot without x-axis labels\n",
    "plot_perturbations_no_xlabels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perturbations_no_spacing_in_groups(df, output_file='perturbations_no_spacing_in_groups.pdf'):\n",
    "    categories = [\"Typos\", \"Entity Replacement\", \"Dialect-Pidgin\", \"Negation\"]\n",
    "    num_categories = len(categories)\n",
    "    \n",
    "    # Split the data into without CN and with CN\n",
    "    df_no_cn = df.iloc[:4]\n",
    "    df_with_cn = df.iloc[4:]\n",
    "    \n",
    "    # Define color map for the models\n",
    "    cmap = cm.get_cmap('virdis', len(df))\n",
    "    colors_no_cn = [cmap(i + len(df_no_cn)) for i in range(len(df_with_cn))] \n",
    "    colors_with_cn = [cmap(i) for i in range(len(df_no_cn))] \n",
    "\n",
    "    # Create subplots for each perturbation type\n",
    "    fig, axes = plt.subplots(1, num_categories, figsize=(6 * num_categories, 4), sharey=True)\n",
    "    bar_width = 1.0  # Bar width\n",
    "    x_spacing = 2.0 # Spacing between groups=\n",
    "\n",
    "    for ax, category in zip(axes, categories):\n",
    "        # Add bars for models without CN\n",
    "        x_positions_no_cn = np.arange(len(df_no_cn))\n",
    "        for i, model in enumerate(df_no_cn[\"Model\"]):\n",
    "            ax.bar(x_positions_no_cn[i], df_no_cn[category].iloc[i], color=colors_no_cn[i], width=bar_width, align='center', label=model if ax == axes[0] else \"\")\n",
    "\n",
    "        # Add bars for models with CN, placed after a gap\n",
    "        x_positions_with_cn = x_positions_no_cn[-1] + x_spacing + np.arange(len(df_with_cn))\n",
    "        for i, model in enumerate(df_with_cn[\"Model\"]):\n",
    "            ax.bar(x_positions_with_cn[i], df_with_cn[category].iloc[i], color=colors_with_cn[i], width=bar_width, align='center', label=model if ax == axes[0] else \"\")\n",
    "        \n",
    "        # Add titles and format axes\n",
    "        ax.set_title(category, fontsize=20)\n",
    "        ax.set_ylim(0.5, 1)\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        ax.set_xticks([])\n",
    "\n",
    "    all_colors = colors_no_cn + colors_with_cn\n",
    "    \n",
    "    # Add a single legend\n",
    "    handles = [plt.Rectangle((0, 0), 1, 1, color=all_colors[i]) for i in range(len(all_colors))]\n",
    "    fig.legend(handles, df[\"Model\"], loc='lower center', ncol=len(df), bbox_to_anchor=(0.5, -0.1), fontsize=14, frameon=False)\n",
    "     # Add a common y-axis label\n",
    "    fig.text(-0.007, 0.5, 'MAP@20', va='center', rotation='vertical', fontdict={'fontsize': 20})\n",
    "\n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(output_file, format='pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to create the plot with no spacing within each group\n",
    "plot_perturbations_no_spacing_in_groups(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement logic to create parallel dataset sentences for each perturbation type\n",
    "# Load the generations from GPT4o\n",
    "perturbation_path = '/home/kebl7383/claim-matching-robustness/experiments/named_entity_replacement/gpt4o/clef2021-checkthat-task2a--english/train_worstcase_named_entity_replacements_verified.jsonl'\n",
    "\n",
    "verified_df = pd.read_json(perturbation_path, lines=True)\n",
    "\n",
    "def parse_rewritten_tweets(text):\n",
    "    \"\"\"\n",
    "    Parses a given string of rewritten tweets into a list of individual tweets.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string containing rewritten tweets.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of individual rewritten tweets.\n",
    "    \"\"\"\n",
    "    # Split the text by lines and filter out any empty lines\n",
    "    lines = [line.strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "\n",
    "    # Extract tweets after the colon \": \" in lines that start with \"Rewritten Tweet\"\n",
    "    tweets = [\n",
    "        line.split(\": \", 1)[1]\n",
    "        for line in lines\n",
    "        if line.startswith(\"Rewritten Tweet\") and \": \" in line\n",
    "    ]\n",
    "\n",
    "    return tweets\n",
    "\n",
    "\n",
    "def parse_rewritten_tweets(text):\n",
    "    \"\"\"\n",
    "    Parses a given string of rewritten tweets into a list of individual tweets.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string containing rewritten tweets.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of individual rewritten tweets.\n",
    "    \"\"\"\n",
    "    # Handle cases where the text may not have proper newlines between tweets\n",
    "    tweets = []\n",
    "    for segment in text.split(\"Rewritten Tweet\"):\n",
    "        # Ignore empty segments or ones without valid content\n",
    "        if not segment.strip():\n",
    "            continue\n",
    "        # Extract the tweet number and content after \":\"\n",
    "        parts = segment.split(\":\", 1)\n",
    "        if len(parts) > 1:\n",
    "            tweet = parts[1].replace(\"\\n\", \"\").replace(\"\\\\n\", \"\").strip()\n",
    "            tweets.append(tweet)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_response = verified_df.sample(n=1)['rewrites'].values[0]\n",
    "parse_rewritten_tweets(sample_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_claims = []\n",
    "for idx, row in verified_df.iterrows():\n",
    "    rewrites = parse_rewritten_tweets(str(row[\"rewrites\"]))\n",
    "    # If json loads fails, skip the row\n",
    "    try:\n",
    "        verified_labels = json.loads(row[\"verification\"])[\"labels\"]\n",
    "    except:\n",
    "        continue\n",
    "    # Get indices where the label is 1\n",
    "    verified_idx = [\n",
    "        idx for idx, label in enumerate(verified_labels) if label == 1\n",
    "    ]\n",
    "    # Loop through the verified indices\n",
    "    for idx in verified_idx:\n",
    "        # Add the original claim and rewritten claim to their respective lists\n",
    "        orig_json = {\n",
    "            \"query_id\": row[\"query_id\"],\n",
    "            \"original_query\": row[\"query\"],\n",
    "            \"perturbed_query\": rewrites[idx],\n",
    "        }\n",
    "        perturbed_claims.append(orig_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(perturbed_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_replaced_df = pd.DataFrame(perturbed_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_replaced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dialect changes\n",
    "perturbation_path = \"/home/kebl7383/claim-matching-robustness/experiments/dialect/gpt4o/clef2021-checkthat-task2a--english/train_dialect_rewrites_verified.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_verified_df = pd.read_json(perturbation_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rewritten_old_tweets(text):\n",
    "    \"\"\"\n",
    "    Parses a given string of rewritten tweets into a list of individual tweets.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string containing rewritten tweets.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of individual rewritten tweets.\n",
    "    \"\"\"\n",
    "    # Split the text by lines and filter out any empty lines\n",
    "    lines = [line.strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "\n",
    "    # Extract tweets after the colon \": \" in lines that start with \"Rewritten Tweet\"\n",
    "    tweets = [\n",
    "        line.split(\": \", 1)[1]\n",
    "        for line in lines\n",
    "        if line.startswith(\"Rewritten Tweet\") and \": \" in line\n",
    "    ]\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_perturbed_claims = []\n",
    "for idx, row in dialect_verified_df.iterrows():\n",
    "    rewrites = parse_rewritten_old_tweets(str(row[\"rewrites\"]))\n",
    "    # If json loads fails, skip the row\n",
    "    try:\n",
    "        verified_labels = json.loads(row[\"verification\"])[\"labels\"]\n",
    "    except:\n",
    "        continue\n",
    "    # Get indices where the label is 1\n",
    "    verified_idx = [\n",
    "        idx for idx, label in enumerate(verified_labels) if label == 1\n",
    "    ]\n",
    "    # Loop through the verified indices\n",
    "    for idx in verified_idx:\n",
    "        # Add the original claim and rewritten claim to their respective lists\n",
    "        orig_json = {\n",
    "            \"query_id\": row[\"query_id\"],\n",
    "            \"original_query\": row[\"query\"],\n",
    "            \"perturbed_query\": rewrites[idx],\n",
    "        }\n",
    "        dialect_perturbed_claims.append(orig_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_perturbed_df = pd.DataFrame(dialect_perturbed_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_perturbed_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_perturbed_df.shape, entity_replaced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load typos\n",
    "typos_perturbation_path = \"/home/kebl7383/claim-matching-robustness/experiments/typos/gpt4o/clef2021-checkthat-task2a--english/train_llm_typos_verified.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typos_verified_df = pd.read_json(typos_perturbation_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typos_perturbed_claims = []\n",
    "for idx, row in typos_verified_df.iterrows():\n",
    "    rewrites = parse_rewritten_old_tweets(str(row[\"rewrites\"]))\n",
    "    # If json loads fails, skip the row\n",
    "    try:\n",
    "        verified_labels = json.loads(row[\"verification\"])[\"labels\"]\n",
    "    except:\n",
    "        continue\n",
    "    # Get indices where the label is 1\n",
    "    verified_idx = [\n",
    "        idx for idx, label in enumerate(verified_labels) if label == 1\n",
    "    ]\n",
    "    # Loop through the verified indices\n",
    "    for idx in verified_idx:\n",
    "        # Add the original claim and rewritten claim to their respective lists\n",
    "        orig_json = {\n",
    "            \"query_id\": row[\"query_id\"],\n",
    "            \"original_query\": row[\"query\"],\n",
    "            \"perturbed_query\": rewrites[idx],\n",
    "        }\n",
    "        typos_perturbed_claims.append(orig_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typos_perturbed_df = pd.DataFrame(typos_perturbed_claims) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typos_perturbed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dialect_perturbed_df.shape[0] + entity_replaced_df.shape[0] + typos_perturbed_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the negation changes\n",
    "negation_perturbation_path = \"/home/kebl7383/claim-matching-robustness/experiments/negation/gpt4o/clef2021-checkthat-task2a--english/train_worstcase_negation_verified.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_verified_df = pd.read_json(negation_perturbation_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_claims(markdown_json_string):\n",
    "    \"\"\"\n",
    "    Parses a JSON string formatted with Markdown-style backticks and returns the list of claims.\n",
    "\n",
    "    Args:\n",
    "        markdown_json_string (str): A string containing JSON wrapped in Markdown backticks.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of claims from the JSON or an empty list if no claims are found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove Markdown formatting (backticks and optional language labels)\n",
    "        cleaned_json_string = re.sub(\n",
    "            r\"```(?:json)?\\n\", \"\", markdown_json_string.strip()\n",
    "        ).strip(\"`\")\n",
    "\n",
    "        # Parse the cleaned JSON string\n",
    "        parsed_data = json.loads(cleaned_json_string)\n",
    "\n",
    "        # Return the list of claims\n",
    "        return parsed_data.get(\"negated_claims\", [])\n",
    "    except (json.JSONDecodeError, AttributeError) as e:\n",
    "        # Handle errors gracefully and return an empty list\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = negation_verified_df.sample(n=1)['rewrites'].values[0]\n",
    "parse_claims(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_perturbed_claims = []\n",
    "for idx, row in negation_verified_df.iterrows():\n",
    "    print(f'We are here {idx}')\n",
    "    rewrites = parse_claims(row[\"rewrites\"])\n",
    "    # If json loads fails, skip the row\n",
    "    try:\n",
    "        verified_labels = json.loads(row[\"verification\"])[\"labels\"]\n",
    "    except:\n",
    "        continue\n",
    "    # Get indices where the label is 1\n",
    "    verified_idx = [\n",
    "        idx for idx, label in enumerate(verified_labels) if label == 1\n",
    "    ]\n",
    "    # Loop through the verified indices\n",
    "    for idx in verified_idx:\n",
    "        # Add try catch block to handle errors\n",
    "        try:\n",
    "            # Add the original claim and rewritten claim to their respective lists\n",
    "            orig_json = {\n",
    "                \"query_id\": row[\"query_id\"],\n",
    "                \"original_query\": row[\"query\"],\n",
    "                \"perturbed_query\": rewrites[idx],\n",
    "            }\n",
    "            negation_perturbed_claims.append(orig_json)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(negation_perturbed_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_perturbed_df = pd.DataFrame(negation_perturbed_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dialect_perturbed_df.shape[0] + entity_replaced_df.shape[0] + typos_perturbed_df.shape[0] + negation_perturbed_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = pd.concat([dialect_perturbed_df, entity_replaced_df, typos_perturbed_df, negation_perturbed_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs.to_csv('train_perturbed_queries_lite.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate combinatorial pairs\n",
    "def generate_combinatorial_pairs(df):\n",
    "    result = []\n",
    "    for query_id, group in df.groupby(\"query_id\"):\n",
    "        # Generate all combinations of perturbed_query pairs\n",
    "        perturbed_queries = group[\"perturbed_query\"].tolist()\n",
    "        pairs = combinations(perturbed_queries, 2)\n",
    "        for pair in pairs:\n",
    "            result.append({\n",
    "                \"query_id\": query_id,\n",
    "                \"original_query\": pair[0],\n",
    "                \"perturbation_query\": pair[1]\n",
    "            })\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "# Generate the test file\n",
    "test_df = generate_combinatorial_pairs(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df[\"query_id\"] == \"tweet-sno-4\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output as CSV\n",
    "test_df.to_csv('train_perturbed_queries_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lite file\n",
    "lite_df = pd.read_csv('train_perturbed_queries_lite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lite_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Get unique query IDs\n",
    "unique_query_ids = lite_df['query_id'].unique()\n",
    "\n",
    "# Step 2: Split the unique IDs into train and evaluation sets\n",
    "train_ids, eval_ids = train_test_split(unique_query_ids, test_size=0.10, random_state=42)\n",
    "\n",
    "# Step 3: Split the original DataFrame based on the IDs\n",
    "train_df = lite_df[lite_df['query_id'].isin(train_ids)]\n",
    "eval_df = lite_df[lite_df['query_id'].isin(eval_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the resulting DataFrames\n",
    "train_df.shape, eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lite train and eval files\n",
    "train_df.to_csv('train_perturbed_queries_lite_train.csv', index=False)\n",
    "eval_df.to_csv('train_perturbed_queries_lite_eval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('train_perturbed_queries_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Get unique query IDs\n",
    "unique_query_ids = full_df['query_id'].unique()\n",
    "\n",
    "# Step 2: Split the unique IDs into train and evaluation sets\n",
    "train_ids, eval_ids = train_test_split(unique_query_ids, test_size=0.10, random_state=42)\n",
    "\n",
    "# Step 3: Split the original DataFrame based on the IDs\n",
    "full_train_df = full_df[full_df['query_id'].isin(train_ids)]\n",
    "full_eval_df = full_df[full_df['query_id'].isin(eval_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df.shape, full_eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lite train and eval files\n",
    "train_df.to_csv('train_perturbed_queries_full_train.csv', index=False)\n",
    "eval_df.to_csv('train_perturbed_queries_full_eval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
